# Data Engineering at One King's Lane

One Kings Lane sell products. Seems easy enough. All you need to do is
record what you sell. Oh, right, we probably should be recording where
we're buying the products, and how much we're paying for them
too. Hmm, we probably should track their performance so we're making
sure that we're only selling the best of the best for home
furnishings.  It'd probably also be good if our merchandisers could
tell our vendors which of their products do well, so we can get more
of them.  Ah, and with so many products, it'd be great to help guide
our customers through them with recommendations... and search... and
filtering by attributes... and extracting non-obvious attributes.


The bottom line is: Everyone. Needs. Data. And that's where we come in!

As a member of the data engineering team at One Kings Lane, you'll be
in the business of data fulfillment: making sure data gets to the
people who need it on schedule, and on a platform that will works for
the way they will consume their data.  You'll be working alongside a
passionate and dedicated team.


# Position: Data Engineering - Infrastructure & Operations (Data Ops)

The Data Ops role is an integral part of the OKL Data Engineering
team. This role is responsible for having a deep understanding of the
inner workings of the hardware and software systems that we make use
of to stay in the business of data fulfillment.  This position will
help you develop a deep understanding of several new and up and coming
technologies, how they're used to accomplish the processing and
warehousing of large volumes of data, and how they're cross
integrated. This role will work closely with the other members of the
data engineering team to ensure that best practices are followed for
the processing or warehousing of data on the target platforms, as they
will be the chief experts in those platforms' inner workings.


More concisely:
 * Become an expert on the inner workings of a number of data integration systems and tools
 * Enhance and simplify the maintenance of our data integration systems, and data flows.
 * Champion of performance, scalability, and reliability for our data feeds and flows
 * Manage application lifecycle and deployment to cloud and non-cloud servers
 * Build tools to monitor the integrity of the end-to-end data flow
 * Be a first responder and provide triage for data issues
 * Involve yourself in the dynamic world of data security and access control
 * Ensure the overall health of our infrastructure

In a nutshell: You love having a deep understanding of how systems
work, love automation, and believe that you can create a world run by
machines with you own two hands, keyboard, and cup of coffee. You love
the idea of having robust, self-healing systems and that's a goal
worth marching toward.


# Qualifications and Required Skills

 * Bachelor's Degree
 * A commitment to writing understandable, maintainable, and reusable
   software
 * A strong sense of teamwork
 * Great verbal and oral communication skills
 * Work effectively individually as well as part of a group
 * An innate desire to deliver
 * Excited by the prospect of learning and working with new or unconventional technologies
 * Proficiency with Unix/Linux process troubleshooting and log spelunking

# Desired Skills

 Though not required, having experience in any of the following areas would be a boon

 * Data Integration Technologies
 * Databases (SQL and NoSQL)
 * Cloud services deployment
 * Data Warehousing
 * Automation (e.g. Ansible, Chef, Capistrano, automated deployment etc)
 * Clojure, Ruby, Java, Python, and/or Shell scripting
